{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1945d9b-c79e-42a4-a688-14c81e670f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import ks_2samp, entropy\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# ---------- Q scorer (uses your DACV) ----------\n",
    "def score_quality_Q(real_df: pd.DataFrame, syn_df: pd.DataFrame, target_col=\"Target\"):\n",
    "    cols = [c for c in real_df.columns if c != target_col]\n",
    "    cat_cols = [c for c in cols if real_df[c].dtype == \"object\"]\n",
    "    num_cols = [c for c in cols if c not in cat_cols]\n",
    "\n",
    "    # D (numeric hist/KS/JSD + RC; categorical TVD)\n",
    "    def js_divergence(p, q, base=np.e):\n",
    "        p = np.asarray(p, dtype=float); q = np.asarray(q, dtype=float)\n",
    "        p = p / (p.sum() + 1e-12); q = q / (q.sum() + 1e-12)\n",
    "        m = 0.5*(p+q); \n",
    "        return 0.5*entropy(p, m, base=base)+0.5*entropy(q, m, base=base)\n",
    "    def hist_compare(xr, xs, bins=30, rng=None, smooth=1e-9):\n",
    "        if rng is None:\n",
    "            lo = np.nanmin(np.concatenate([xr, xs])); hi = np.nanmax(np.concatenate([xr, xs])); \n",
    "            if lo==hi: hi = lo+1.0; rng=(lo,hi)\n",
    "        hr, edges = np.histogram(xr, bins=bins, range=rng)\n",
    "        hs, _     = np.histogram(xs, bins=bins, range=rng)\n",
    "        pr = (hr + smooth) / (hr.sum() + smooth*bins)\n",
    "        ps = (hs + smooth) / (hs.sum() + smooth*bins)\n",
    "        return {\"jsd\": float(js_divergence(pr, ps))}\n",
    "    def tvd_from_counts(p, q):\n",
    "        keys = sorted(set(p).union(q), key=str)\n",
    "        pv = np.array([p.get(k, 0.0) for k in keys], dtype=float)\n",
    "        qv = np.array([q.get(k, 0.0) for k in keys], dtype=float)\n",
    "        return 0.5 * np.abs(pv - qv).sum()\n",
    "\n",
    "    D_parts = []\n",
    "    for c in num_cols:\n",
    "        xr = real_df[c].dropna().values; xs = syn_df[c].dropna().values\n",
    "        if xr.size and xs.size:\n",
    "            ks = ks_2samp(xr, xs).statistic\n",
    "            jsd = hist_compare(xr, xs)[\"jsd\"]\n",
    "            lo, hi = np.nanmin(xr), np.nanmax(xr)\n",
    "            rc = float(np.mean((xs>=lo)&(xs<=hi)))\n",
    "            D_parts.append( (1-ks, 1-jsd, rc) )\n",
    "    D_score = np.mean([np.mean(p) for p in D_parts]) if D_parts else np.nan\n",
    "\n",
    "    real_cat = real_df[cat_cols].copy().astype(str)\n",
    "    syn_cat  = syn_df[cat_cols].copy().astype(str)\n",
    "    tvds=[]\n",
    "    for c in cat_cols:\n",
    "        pr = real_cat[c].value_counts(normalize=True).to_dict()\n",
    "        ps = syn_cat[c].value_counts(normalize=True).to_dict()\n",
    "        tvds.append(1.0 - tvd_from_counts(pr, ps))\n",
    "    D_cat = float(np.mean(tvds)) if tvds else np.nan\n",
    "\n",
    "    # C (assoc)\n",
    "    def spearman_matrix(df, cols):\n",
    "        m=len(cols); R=np.ones((m,m))*np.nan\n",
    "        for i,a in enumerate(cols):\n",
    "            for j,b in enumerate(cols):\n",
    "                if i==j: R[i,i]=1.0\n",
    "                elif i<j:\n",
    "                    rho,_=spearmanr(df[a], df[b], nan_policy=\"omit\")\n",
    "                    R[i,j]=R[j,i]=rho\n",
    "        return R\n",
    "    C_num=np.nan\n",
    "    if len(num_cols)>=2:\n",
    "        Rr=spearman_matrix(real_df,num_cols); Rs=spearman_matrix(syn_df,num_cols)\n",
    "        mask = np.isfinite(Rr)&np.isfinite(Rs)\n",
    "        C_num = float(1.0 - np.nanmean(np.abs(Rr[mask]-Rs[mask])))\n",
    "\n",
    "    def nmi_matrix(df, cols):\n",
    "        m=len(cols); M=np.ones((m,m))*np.nan\n",
    "        for i,a in enumerate(cols):\n",
    "            for j,b in enumerate(cols):\n",
    "                if i==j: M[i,i]=1.0\n",
    "                elif i<j: M[i,j]=M[j,i]=normalized_mutual_info_score(df[a].astype(str), df[b].astype(str))\n",
    "        return M\n",
    "    C_cat=np.nan\n",
    "    if len(cat_cols)>=2:\n",
    "        Mr=nmi_matrix(real_cat,cat_cols); Ms=nmi_matrix(syn_cat,cat_cols)\n",
    "        mask=np.isfinite(Mr)&np.isfinite(Ms)\n",
    "        C_cat = float(1.0 - np.nanmean(np.abs(Mr[mask]-Ms[mask])))\n",
    "\n",
    "    # V (coverage)\n",
    "    CC=[]\n",
    "    for c in cat_cols:\n",
    "        pr=real_cat[c].value_counts(normalize=True)\n",
    "        ps=syn_cat[c].value_counts(normalize=True)\n",
    "        cats=set(pr.index)\n",
    "        cc=float(np.mean([k in ps.index for k in cats]))\n",
    "        CC.append(cc)\n",
    "    V_score = float(np.mean(CC)) if CC else np.nan\n",
    "\n",
    "    # aggregate (weights like your cell)\n",
    "    parts = []\n",
    "    for x in [D_score, D_cat, C_num, C_cat, V_score]:\n",
    "        if not np.isnan(x): parts.append(x)\n",
    "    Q = float(np.mean(parts)) if parts else 0.0\n",
    "    return Q\n",
    "\n",
    "# ---------- P scorer (your DCR, Qδ, I) ----------\n",
    "def score_privacy_P(real_df: pd.DataFrame, syn_df: pd.DataFrame, target_col=\"Target\"):\n",
    "    cols = [c for c in real_df.columns if c != target_col]\n",
    "    cat_cols = [c for c in cols if real_df[c].dtype == \"object\"]\n",
    "    num_cols = [c for c in cols if c not in cat_cols]\n",
    "\n",
    "    def make_ohe():\n",
    "        try: return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError: return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "    enc = ColumnTransformer([\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", make_ohe(),    cat_cols),\n",
    "    ])\n",
    "    X_real = enc.fit_transform(real_df[cols]); X_fake = enc.transform(syn_df[cols])\n",
    "\n",
    "    # DCR\n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(X_real)\n",
    "    dists,_ = nn.kneighbors(X_fake); dists=dists.ravel()\n",
    "    DCR_mean = float(np.mean(dists))\n",
    "\n",
    "    # Qδ\n",
    "    quantiles = np.linspace(0.05,0.95,19); qd_vals=[]\n",
    "    for c in num_cols:\n",
    "        xr = np.asarray(real_df[c].dropna().values)\n",
    "        xs = np.asarray(syn_df[c].dropna().values)\n",
    "        if xr.size and xs.size:\n",
    "            qr = np.quantile(xr, quantiles); qs = np.quantile(xs, quantiles)\n",
    "            qd_vals.append(float(np.mean(np.abs(qr-qs))))\n",
    "    Q_delta = float(np.mean(qd_vals)) if qd_vals else float(\"nan\")\n",
    "\n",
    "    # I\n",
    "    def norm_df(df, cols):\n",
    "        out=df[cols].copy()\n",
    "        for c in cols:\n",
    "            if np.issubdtype(out[c].dtype, np.number): out[c]=out[c].round(6)\n",
    "            else: out[c]=out[c].astype(str).str.strip()\n",
    "        return out\n",
    "    real_norm = norm_df(real_df, cols); fake_norm = norm_df(syn_df, cols)\n",
    "    dup_within_synth = float(1.0 - len(fake_norm.drop_duplicates())/max(1,len(fake_norm)))\n",
    "    set_real=set(map(tuple, real_norm.to_numpy())); set_fake=set(map(tuple, fake_norm.to_numpy()))\n",
    "    overlap_between = float(len(set_real & set_fake)/max(1,len(fake_norm)))\n",
    "\n",
    "    # map to [0,1] scores (same idea as your cell)\n",
    "    def normalize01(x, lo=0.0, hi=1.0):\n",
    "        if np.isnan(x): return np.nan\n",
    "        if hi==lo: return 0.0\n",
    "        v=(x-lo)/(hi-lo); return float(max(0.0, min(1.0, v)))\n",
    "    def inv01(x, cap=1.0):\n",
    "        if np.isnan(x): return np.nan\n",
    "        return float(max(0.0, min(1.0, 1.0 - x/cap)))\n",
    "\n",
    "    d95 = float(np.percentile(dists, 95)) if len(dists) else 1.0\n",
    "    DCR_score = normalize01(DCR_mean, lo=0.0, hi=d95 if d95>0 else 1.0)\n",
    "    Qd_cap = float(np.nanmedian(qd_vals))*4 if qd_vals else (abs(Q_delta)+1e-6)\n",
    "    Qdelta_score = inv01(Q_delta, cap=Qd_cap if Qd_cap>0 else 1.0)\n",
    "    I_combined = 0.5*(dup_within_synth + overlap_between)\n",
    "    I_score = inv01(I_combined, cap=0.10)\n",
    "\n",
    "    P = 0.5*DCR_score + 0.3*Qdelta_score + 0.2*I_score\n",
    "    return float(P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
